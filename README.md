# NLP2
CEIA FIUBA - Natural Language Processing 2

Author: Braian Desía (b.desia@hotmail.com)

## About this project

This repository contains different challenges solved during the course.

## Project structure

The project was structured as follows. 

```
├── data                                # Data. Here you can find cvs used for challenge 2.
├── demos                               # Damostrations. Here you can find demostrations for challenge 2.
├── exports                             # Here you can find saved chats with CV consultant bot.
├── notebooks                           # Jupyter notebooks
├── src                                 # Main source of the project
└── temp                                # Temporal files. Here you can find temp files generated by CV consultant bot.
```

## Prerequisites

- Python > 3.11
- Poetry 2.1.4

## Running the project

### Locally (bash)

Follow this steps:
1. Clone the repository in your local machine.
1. Run `setup.sh` in a bash console (e.g. Git Bash). 

    ```bash
    ./setup.sh
    ```

    This script will execute poetry for installing all the dependencies and create a virtual environment. This script will aslso setup your `PYTHONPATH` by creating a `pth` file in the project virtual environment.
1. Activate the poetry environment (just in case):

    ```bash
    poetry env activate
    ```
1. Now, you're ready to run the notebooks and source code.

## Challenges

**Challenge #1: TinyGPT**

Implementation of a lightweight GPT-like model using Mixture of Experts (MoE) architecture.

*Main features*
- Transformer decoder-only architecture.
- Mixture of Experts (MoE) layers for efficiency.
- Sampling strategies: temperature, top-k and top-p (nucleus sampling).
- Training loop and text generation utilities.

*Notebook:* [notebooks/TP1_TinyGPT.ipynb](notebooks/TP1_TinyGPT.ipynb)

**Challenge #2: CV reader**

A question-answering bot over a collection of CVs using dense retrieval with Pinecone vector database.

*Main features*
- Document embedding with **all-MiniLM-L6-v2** model via Sentence-Transformers.
- Pinecone index creation and upsert.
- Real-time semantic search with metadata filtering.
- Answer generation powered by **llama-3.3-70b-versatile** model via Groq.
- Interactive **Streamlit** web app.
- Streamlit interface for interactive querying.

*source code:*
- cv_streamlit_app.py
- pinecone_registry.py

*Run locally:* 
First, create an environment file ".env" and add your keys:

    ```bash
    PINECONE_API_KEY = your_pinecone_api_key
    GROQ_API_KEY = your_groq_api_key
    ```
Then:

    ```bash
    poetry run streamlit run src/cv_streamlit_app.py
    ```
*Video demostration:* [demos/demo_tp2_CVanalyzer.mp4](demos/demo_tp2_CVanalyzer.mp4)

**Challenge #3: CV Multi-Agent System**

A multi-agent question-answering system over a collection of CVs with intelligent routing per person and built-in comparison capabilities.

**Main features**
- Support for multiple CVs in a single vector database (one CV per individual).
- Document embedding using **all-MiniLM-L6-v2** (Sentence-Transformers).
- Pinecone serverless index (AWS us-east-1) with metadata filtering by person.
- Automatic detection of person names in user queries (lightweight NER powered by LLM).
- Multi-agent architecture:
  - One specialized agent per person → answers using only that candidate’s CV.
  - Supervisor agent that aggregates and compares responses when the query involves multiple people.
- Answer generation powered by **llama-3.3-70b-versatile** via Groq.
- Fully interactive Streamlit web app with persistent chat history.
- Export chat as Markdown with one click.
- Full support for comparative questions:
  - “Who has more Python experience between John Doe and Jane Smith?”
  - “Compare the academic background of Alice Johnson and Bob Lee”

**Source code**
- `cvagent_streamlit_app.py` → main app with multi-agent logic
- `pinecone_registry.py` → enhanced wrapper with person-based metadata filtering. View class `pinecone_registry4agent.py`.

*Run locally:* 
First, create an environment file ".env" and add your keys:

    ```bash
    PINECONE_API_KEY = ´your_pinecone_api_key´
    GROQ_API_KEY = ´your_groq_api_key´
    ```
Then:

    ```bash
    poetry run streamlit run src/cvagent_streamlit_app.py
    ```
<!-- *Video demostration:* [demos/demo_tp3_CVagent.mp4](demos/demo_tp3_CVagent.mp4) -->








